---
knit: bookdown::preview_chapter
---

# Pedestrian counting sensor data

```{r ped-pkgs, echo = FALSE}
library(tidyverse)
```

## Overview

* metadata: temperatures & rainfall

The City of Melbourne has sensors set up in strategic locations across the inner city to keep hourly tallies of pedestrians. The data is updated on a monthly basis and available for download from [Melbourne Open Data Portal](https://data.melbourne.vic.gov.au/Transport/Pedestrian-Counting-System-2009-to-Present-counts-/b2ak-trbp). The **rwalkr** package provides an API to easily access sensor counts and geographic locations in R. In this case study, we focus on the foot traffic of 2018 at 4 sensors.

```{r ped-data}
library(rwalkr)
sensors <- c("Southern Cross Station", "Melbourne Central",
  "Flinders Street Station Underpass", "Birrarung Marr")
peds <- melb_walk_fast(year = 2018, sensor = sensors)
```

```{r ped-sensor, echo = FALSE}
library(ggmap)
library(lubridate)
ped_loc <- pull_sensor() %>% 
  filter(year(installation_date) < 2019, status == "A")
melb_map <- read_rds("data/melb_map.rds")
selected <- ped_loc %>% 
  filter(sensor %in% sensors)
nonselected <- ped_loc %>% 
  filter(!(sensor %in% sensors))
ggmap(melb_map) +
  geom_point(
    data = nonselected, aes(x = longitude, y = latitude),
    colour = "grey70", alpha = 0.8, size = 3
  ) +
  geom_point(
    data = selected, aes(x = longitude, y = latitude, colour = sensor),
    size = 4, shape = 17
  ) +
  xlab("Longitude") +
  ylab("Latitude") +
  scale_colour_brewer(palette = "Dark2", name = "Sensor") +
  guides(col = guide_legend(nrow = 2, byrow = TRUE)) +
  theme(legend.position = "bottom")
```

The map above gives a snapshot of `r nrow(ped_loc)` active sensors in 2018 with 4 selected sensors highlighted. The majority of sensors are installed on the east of the city, where crowds of people are likely to congregate due to various types of activities, such as commuting (Southern Cross Stations and Flinders Street Stations), shopping (Melbourne Central), and cultural events (Birrarung Marr).

## Different temporal patterns

Pedestrian sensor data is a typical temporal data set. We're interested in exploiting temporal patterns at various time resolutions and across different locations. We often start off plotting time series over a whole period. [TODO: describe in detail?]

```{r}
peds %>% 
  ggplot(aes(x = Date_Time, y = Count)) +
  geom_line(size = 0.3) +
  facet_grid(Sensor ~ ., labeller = labeller(Sensor = label_wrap_gen(20))) +
  scale_x_datetime(date_labels = "%d %b %Y", date_minor_breaks = "1 month") +
  xlab("Date Time")
```

However, the overall time series plot cannot reveal peoples' everyday life in detail. We should be able to plot hourly counts against time of the day, shown in Figure ??. This complements Figure ?? by unfolding daily patterns. In particular, there are two distinct clusters popping out from two train stations.

```{r}
peds %>% 
  ggplot(aes(x = Time, y = Count, group = Date)) +
  geom_line(size = 0.3, alpha = 0.3) +
  facet_wrap(~ Sensor, labeller = labeller(Sensor = label_wrap_gen(20)))
```

We further tease out work versus non-work days to explain variations arisen from these disparities. Except for Birrarung Marr, the most dominant pattern is driven by the workforce, with commuters' spikes at 8am and 5pm and a lunch hour rush. These spikes are completely absent on weekends and public holidays.

```{r}
hol2018 <- tsibble::holiday_aus(2018, state = "VIC") %>% 
  bind_rows(tibble(holiday = "AFL", date = ymd("20180929")))
workday <- fct_inorder(c("Work day", "Non-work day"))
peds <- peds %>% 
  mutate(
    Day = wday(Date_Time, label = TRUE, week_start = 1),
    Workday = if_else(
      (Date %in% hol2018$date) | Day %in% c("Sat", "Sun"),
      workday[2], workday[1])
  )
```

```{r}
peds %>% 
  ggplot(aes(x = Time, y = Count, group = Date)) +
  geom_line(size = 0.3, alpha = 0.3) +
  facet_grid(Sensor ~ Workday, labeller = labeller(Sensor = label_wrap_gen(20)))
```

## Effects of other information

## Setting up coffee business

We can investigate the working force pattern a bit more closer by location. Rescaling the counts for each location reveals the difference in patterns much more clearly and shows the three workforce spikes much more pronounced (cf Figure \@ref(fig:ped_adjcounts)).

```{r peds-adjcounts, fig.cap="Adjusted counts of pedestrians reveals the three workforce spikes on weekdays more clearly.", out.width='80%', fig.asp=.75, fig.align='center', message=FALSE, warning = FALSE}
weekhourlies <- peds %>% group_by(Sensor, Weekday, Time) %>%
  summarize(Count = median(Count, na.rm=TRUE))
weekhourlies <- weekhourlies %>% group_by(Sensor) %>% 
  mutate(adjCount = scale(Count))

ggplot(aes(x=Time, y=adjCount), data=weekhourlies) + facet_grid(.~Weekday) + geom_line(aes(group=Sensor))
```

Figure \@ref(fig:loc-cluster) gives an overview of the hourly pattern observed at each location. Locations are grouped by their pattern, resulting into three groups, that can be described mostly by their pedestrian counts at 8am, noon, and 5pm. One ofthe groups shows a strong morning and afternoon peak, with only a slight increase during lunch. The other two groups are not nearly as much affected by the pedestrian rush hours. One group shows almost the same pattern on weekdays as on weekends (with tiny spikes added on weekdays), while pedestrian traffic for the last groups is generally higher for the last group on weekdays than on weekends and increases during the day until peaking at 5pm. 

```{r loc-cluster, fig.cap="Location of sensors clustered by observed patterns of pedestrian counts.", out.width='80%', fig.asp=.75, fig.align='center', message=FALSE, warning = FALSE}
hourlies <- weekhourlies %>% group_by(Time, Sensor) %>% summarize(
  adjCount = mean(adjCount, na.rm=TRUE)
)
adjcounts <- hourlies %>% spread(Time, adjCount)
dists <- dist(adjcounts[,-1])
pedclust <- hclust(dists)
adjcounts$Group <- cutree(pedclust, k=3)

weekhourlies <- merge(weekhourlies[1:nrow(weekhourlies),], adjcounts[, c("Sensor", "Group")], by="Sensor", all.x=TRUE)
ggplot(aes(x=Time, y=Count), data=weekhourlies) + facet_grid(Group~Weekday) + geom_line(aes(group=Sensor, colour=factor(Group))) + scale_colour_brewer(palette="Dark2")
```

The [geographic location of the sensors](https://data.melbourne.vic.gov.au/Transport-Movement/Pedestrian-Sensor-Locations/ygaw-6rzq) is made available through the Melbourne Data initiative. A copy of the data is available locally. What we would like to do with this data, is to plot the sensors on a map of Melbourne, coloured by the grouping that we just identified to get an idea of whether the groupings have a geographical interpretation as well. 
```{r eval=FALSE}
sensors <- read.csv("data/Pedestrian_Sensor_Locations.csv")
```
Unfortunately, we cannot match the names of the locations directly, because they are formatted (slightly) differently between the two sources. The sensor location data set e.g. contains the string Lygon St (West), whereas the pedestrian count data contains the same location encoded as Lygon.St..West. (note the . introduced by R as a substitute for any special character such as a white space in a variable name).
In order to match these locations, we make use of fuzzy matching as implemented in `adist`, which is based on the generalized Levenshtein distance:
```{r eval=FALSE}
src1 <- as.character(sensors$Sensor.Description)
src2 <- as.character(unique(weekhourlies$Location))

dist.name<-adist(src1, src2, partial = TRUE, ignore.case = TRUE)
dim(dist.name)
```
This distance is an integer value of essentially the number of differences between two character strings. We will pick the minimum for each of the pairs to match the locations strings.

```{r eval=FALSE}
mins <- apply(dist.name, MARGIN=1, FUN=which.min)
sensors$Location <- unique(weekhourlies$Location)[mins]
```
We should also investigate the actual distance values to make sure that we did not accidentally match things that we should not have matched:
```{r eval=FALSE}
sensors$MatchQuality <- apply(dist.name, MARGIN=1, FUN=min)
summary(sensors$MatchQuality)
sensors <- sensors[order(sensors$MatchQuality),]
tail(sensors)[,c("Location", "Sensor.Description")]
```
These matches all look good except for two: `Lonsdale St-Spring St (West)` and `Fitzroy Gardens Visitor Centre` should probably not be matched at all (these two sensors are not actually included in the pedestrian count data at this time). We will set those two locations to NA, and then match via Location to include the grouping information:
```{r eval=FALSE}
sensors$Location[sensors$Sensor.Description %in% c("Lonsdale St-Spring St (West)","Fitzroy Gardens Visitor Centre")] <- NA
sensors <- merge(sensors, weekhourlies[,c("Location", "Group")], by="Location")
```
Now we want to put this information on a map:
```{r ped-map, fig.cap="Map of inner Melbourne. Locations of sensors are indicated by dots, colour indicates their group.", out.width='80%', fig.asp=.75, fig.align='center', message=FALSE, warning = FALSE, eval=FALSE}
library(ggmap)
library(ggthemes)
melb <- get_map("Melbourne, Australia", zoom=14) # we need to set the zoom - the auto-zoom includes too much. 
ggmap(melb, extent="normal") + 
  geom_point(aes(x=Longitude, y=Latitude, colour=factor(Group)), data=sensors, size=3) + theme_map() +
  scale_colour_brewer(palette="Dark2")
```
***Does the grouping shown in Figure \@ref(fig:ped-map) make sense to somebody who knows  Melbourne?***


Coming back to the general pattern of the graphic we started out with in Figure \@ref(fig:peds-counts), we see that
generally, things are quiet at 5 am, particularly on weekdays. There are, however, some notable exceptions with pedestrian counts of more than 1000 between 5 and 6 in the morning: 
```{r eval=FALSE}
subset(mpeds, Hour==5 & Count > 1000)
```
In the current data set (Dec 2015 - Feb 2016) these counts occurred in eight locations on February 21, 2016, which is when Melbourne hosted its annual White Night in 2016.
Besides New Year's morning on the corner of Flinders and Swanston Street, City Square was the place to be on December 28 and 29 at five in the morning. *** not sure what was going on on those two dates ***

```{r eval=FALSE}
days <- unique(subset(mpeds, Hour==5 & Count > 1000)[, c("Date", "Location")])
# I want to get the remaining hours for each of the locations. I also want to get the Feb 20 data.
```

```{r eval=FALSE}
ggplot(aes(x=Hour, y=Count, group=interaction(Location, Day)), 
       data=mpeds) + 
  facet_grid(.~Weekday) + 
  geom_line(alpha=0.3) 
```
